# BASIC VARIABLES
dataDir: permanent/data
permanentDir: permanent
transientDir: transient
tempDir: transient

until: "split"
profiling: true

# DATA SOURCES - CRAWLING
hostsFile: ../domains/e-justice.txt

crawler: "wget"
crawlTimeLimit: "48h"

# PREPROCESSING
preprocessor: "warc2preprocess"
ftfy: true
boilerplateCleaning: true
parser: "simple"
html5lib: false

shards: 8 # 2^8 = 256 shards
batches: 1024 # each shard split into chunks of 1024 MB

langs: ['en', 'es', 'nl']
